{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "646ea118",
   "metadata": {},
   "source": [
    "# MindLens-AI — 01: Exploratory Data Analysis\n",
    "\n",
    "Analyze the Reddit Depression dataset to understand class distribution, text characteristics, and key patterns before model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51439a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "from src.preprocessing import (\n",
    "    load_primary_dataset,\n",
    "    preprocess_pipeline,\n",
    "    save_processed,\n",
    ")\n",
    "from src.features import build_tfidf\n",
    "\n",
    "# Style\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 5)\n",
    "plt.rcParams[\"figure.dpi\"] = 100\n",
    "\n",
    "print(\"Setup complete ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e1d8ade",
   "metadata": {},
   "source": [
    "## 1. Load & Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3af3ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw dataset\n",
    "raw_df = load_primary_dataset(\"../data/raw/depression_dataset_reddit_cleaned.csv\")\n",
    "print(f\"Raw dataset: {raw_df.shape[0]} rows, {raw_df.shape[1]} cols\")\n",
    "print(raw_df[\"label\"].value_counts())\n",
    "\n",
    "# Preprocess\n",
    "df = preprocess_pipeline(raw_df, remove_stopwords=False)\n",
    "print(f\"\\nProcessed dataset: {df.shape[0]} rows\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf00472",
   "metadata": {},
   "source": [
    "## 2. Dataset Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2b0209",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\n--- Info ---\")\n",
    "df.info()\n",
    "print(\"\\n--- Describe ---\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec98122c",
   "metadata": {},
   "source": [
    "## 3. Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e36f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "counts = df[\"label\"].value_counts().sort_index()\n",
    "bars = ax.bar([\"No Risk (0)\", \"Risk (1)\"], counts.values, color=[\"#4CAF50\", \"#F44336\"])\n",
    "for bar, val in zip(bars, counts.values):\n",
    "    ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,\n",
    "            str(val), ha=\"center\", fontweight=\"bold\")\n",
    "ax.set_title(\"Class Distribution\", fontsize=14)\n",
    "ax.set_ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Class balance — 0: {counts[0]} ({counts[0]/len(df)*100:.1f}%)  \"\n",
    "      f\"1: {counts[1]} ({counts[1]/len(df)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9825743f",
   "metadata": {},
   "source": [
    "## 4. Text Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e649630",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "features = [\"word_count\", \"char_count\", \"avg_word_length\", \"word_density\", \"unique_word_ratio\"]\n",
    "labels_map = {0: \"No Risk\", 1: \"Risk\"}\n",
    "colors = {0: \"#4CAF50\", 1: \"#F44336\"}\n",
    "\n",
    "for i, feat in enumerate(features):\n",
    "    ax = axes[i // 3][i % 3]\n",
    "    for lab in [0, 1]:\n",
    "        subset = df[df[\"label\"] == lab][feat]\n",
    "        ax.hist(subset, bins=50, alpha=0.6, label=labels_map[lab], color=colors[lab])\n",
    "    ax.set_title(feat, fontsize=12)\n",
    "    ax.legend()\n",
    "\n",
    "# Remove empty subplot\n",
    "axes[1][2].set_visible(False)\n",
    "plt.suptitle(\"Feature Distributions by Class\", fontsize=14, y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcfb0e2",
   "metadata": {},
   "source": [
    "## 5. Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0aefa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "for idx, (lab, title, cmap) in enumerate([(0, \"No Risk\", \"Greens\"), (1, \"Risk\", \"Reds\")]):\n",
    "    text_blob = \" \".join(df[df[\"label\"] == lab][\"text\"].dropna())\n",
    "    wc = WordCloud(width=800, height=400, background_color=\"white\",\n",
    "                   colormap=cmap, max_words=100).generate(text_blob)\n",
    "    axes[idx].imshow(wc, interpolation=\"bilinear\")\n",
    "    axes[idx].set_title(title, fontsize=14)\n",
    "    axes[idx].axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"Word Clouds by Class\", fontsize=16, y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b72bbb",
   "metadata": {},
   "source": [
    "## 6. Top TF-IDF Terms per Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e7715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "for idx, (lab, title, color) in enumerate([(0, \"No Risk — Top 20 TF-IDF\", \"#4CAF50\"),\n",
    "                                            (1, \"Risk — Top 20 TF-IDF\", \"#F44336\")]):\n",
    "    subset_texts = df[df[\"label\"] == lab][\"text\"]\n",
    "    vec, X = build_tfidf(subset_texts, max_features=5000)\n",
    "    mean_tfidf = X.mean(axis=0).A1\n",
    "    top_idx = mean_tfidf.argsort()[-20:]\n",
    "    words = np.array(vec.get_feature_names_out())[top_idx]\n",
    "    scores = mean_tfidf[top_idx]\n",
    "\n",
    "    axes[idx].barh(words, scores, color=color)\n",
    "    axes[idx].set_title(title, fontsize=12)\n",
    "    axes[idx].set_xlabel(\"Mean TF-IDF\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f4b2c94",
   "metadata": {},
   "source": [
    "## 7. Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918fc1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"word_count\", \"char_count\", \"avg_word_length\", \"word_density\", \"unique_word_ratio\", \"label\"]\n",
    "corr = df[numeric_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"RdBu_r\", center=0, ax=ax)\n",
    "ax.set_title(\"Feature Correlation Matrix\", fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ebbdf4",
   "metadata": {},
   "source": [
    "## 8. Summary Statistics by Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb08ec91",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = df.groupby(\"label\")[[\"word_count\", \"char_count\", \"avg_word_length\",\n",
    "                               \"word_density\", \"unique_word_ratio\"]].agg([\"mean\", \"median\", \"std\"])\n",
    "summary.columns = [\"_\".join(c) for c in summary.columns]\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d43441",
   "metadata": {},
   "source": [
    "## 9. Save Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f32ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_processed(df, \"../data/processed/primary_clean.csv\")\n",
    "print(\"EDA complete ✓\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
