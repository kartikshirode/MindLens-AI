{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ec139eb",
   "metadata": {},
   "source": [
    "# MindLens-AI — 02: Model Training\n",
    "\n",
    "Train a Logistic Regression baseline with 5-fold cross-validation. Includes GPU check, ROC/PR curves, error analysis, and optional DistilBERT fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8153d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    RocCurveDisplay, PrecisionRecallDisplay,\n",
    "    confusion_matrix, ConfusionMatrixDisplay,\n",
    ")\n",
    "\n",
    "from src.features import build_tfidf\n",
    "from src.model import train_baseline, save_model, get_device\n",
    "from src.evaluation import evaluate_single, cross_validate_model, error_analysis\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"muted\")\n",
    "\n",
    "# --- GPU Check ---\n",
    "device = get_device()\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU detected: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"⚠ No GPU detected — Logistic Regression runs on CPU (fast), DistilBERT will be slow.\")\n",
    "\n",
    "print(\"Setup complete ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce337f40",
   "metadata": {},
   "source": [
    "## 1. Load Processed Data & Build Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e4793b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load processed data (from notebook 01)\n",
    "df = pd.read_csv(\"../data/processed/primary_clean.csv\")\n",
    "print(f\"Loaded {len(df)} samples\")\n",
    "\n",
    "texts = df[\"text\"].values\n",
    "labels = df[\"label\"].values\n",
    "\n",
    "# Build TF-IDF features\n",
    "vectorizer, X = build_tfidf(texts, max_features=5000)\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "print(f\"TF-IDF matrix: {X.shape}\")\n",
    "\n",
    "# Stratified train-test split (80/20)\n",
    "X_train, X_test, y_train, y_test, idx_train, idx_test = train_test_split(\n",
    "    X, labels, np.arange(len(labels)),\n",
    "    test_size=0.2, stratify=labels, random_state=42,\n",
    ")\n",
    "texts_test = texts[idx_test]\n",
    "print(f\"Train: {X_train.shape[0]}  |  Test: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844875a4",
   "metadata": {},
   "source": [
    "## 2. Cross-Validation (5-Fold Stratified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eaf650b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = cross_validate_model(\n",
    "    LogisticRegression,\n",
    "    X, labels,\n",
    "    n_splits=5,\n",
    "    model_kwargs={\"class_weight\": \"balanced\", \"max_iter\": 1000, \"solver\": \"lbfgs\", \"random_state\": 42},\n",
    ")\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3ba6f7",
   "metadata": {},
   "source": [
    "## 3. Train Final Model on Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b5b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline on train split\n",
    "model = train_baseline(X_train, y_train, max_iter=1000)\n",
    "\n",
    "# Evaluate on held-out test set\n",
    "metrics = evaluate_single(model, X_test, y_test)\n",
    "print(\"=== Test Set Results ===\")\n",
    "print(metrics[\"classification_report\"])\n",
    "print(f\"ROC-AUC: {metrics.get('roc_auc', 'N/A'):.4f}\")\n",
    "print(f\"PR-AUC:  {metrics.get('pr_auc', 'N/A'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa18d257",
   "metadata": {},
   "source": [
    "## 4. Confusion Matrix, ROC Curve & PR Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6afd25",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = metrics[\"confusion_matrix\"]\n",
    "ConfusionMatrixDisplay(cm, display_labels=[\"No Risk\", \"Risk\"]).plot(ax=axes[0], cmap=\"Blues\")\n",
    "axes[0].set_title(\"Confusion Matrix\")\n",
    "\n",
    "# ROC Curve\n",
    "RocCurveDisplay.from_estimator(model, X_test, y_test, ax=axes[1])\n",
    "axes[1].set_title(\"ROC Curve\")\n",
    "axes[1].plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "\n",
    "# Precision-Recall Curve\n",
    "PrecisionRecallDisplay.from_estimator(model, X_test, y_test, ax=axes[2])\n",
    "axes[2].set_title(\"Precision-Recall Curve\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0f702c",
   "metadata": {},
   "source": [
    "## 5. Error Analysis (Top 20 FP & FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb6b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fp_df, fn_df = error_analysis(model, X_test, y_test, texts_test, n=20)\n",
    "\n",
    "print(\"=== Top 20 False Positives (predicted Risk but actually No Risk) ===\")\n",
    "for i, row in fp_df.iterrows():\n",
    "    print(f\"\\n[FP-{i+1}] conf={row['confidence']:.3f}\")\n",
    "    print(f\"  {row['text'][:200]}...\")\n",
    "\n",
    "print(\"\\n\\n=== Top 20 False Negatives (predicted No Risk but actually Risk) ===\")\n",
    "for i, row in fn_df.iterrows():\n",
    "    print(f\"\\n[FN-{i+1}] conf={row['confidence']:.3f}\")\n",
    "    print(f\"  {row['text'][:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b30fcae",
   "metadata": {},
   "source": [
    "## 6. Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c5e1de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model + vectorizer for downstream notebooks\n",
    "save_model(model, vectorizer, \"../data/processed/model_artifacts.joblib\")\n",
    "\n",
    "# Also save the test split info for reproducibility\n",
    "import joblib\n",
    "joblib.dump({\n",
    "    \"X_test\": X_test, \"y_test\": y_test, \"texts_test\": texts_test,\n",
    "    \"X_train\": X_train, \"y_train\": y_train,\n",
    "    \"feature_names\": list(feature_names),\n",
    "}, \"../data/processed/test_split.joblib\")\n",
    "print(\"All artifacts saved ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b421acc0",
   "metadata": {},
   "source": [
    "## 7. (Optional) DistilBERT Fine-tuning on GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb992ca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Requires: GPU with ≥4 GB VRAM, transformers, torch\n",
    "\n",
    "from src.model import train_distilbert\n",
    "\n",
    "texts_train_raw = df.iloc[idx_train][\"text\"].values\n",
    "texts_test_raw = df.iloc[idx_test][\"text\"].values\n",
    "\n",
    "trainer, tokenizer = train_distilbert(\n",
    "    train_texts=texts_train_raw,\n",
    "    train_labels=y_train,\n",
    "    val_texts=texts_test_raw,\n",
    "    val_labels=y_test,\n",
    "    epochs=3,\n",
    "    batch_size=16,\n",
    "    output_dir=\"../data/processed/distilbert_model\",\n",
    ")\n",
    "\n",
    "# Evaluate DistilBERT\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"DistilBERT results:\", eval_results)\n",
    "\n",
    "print(\"Model training notebook complete ✓\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
