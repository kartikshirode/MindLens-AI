{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0ca76cb",
   "metadata": {},
   "source": [
    "# MindLens-AI — 05: Robustness Testing (RQ3)\n",
    "\n",
    "**RQ3:** Are model predictions sensitive to small input perturbations (e.g., keyword removal or synonym replacement), indicating reliance on spurious correlations?\n",
    "\n",
    "Tests: keyword removal, synonym replacement. Metric: prediction flip rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc94def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import sys, os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "from src.model import load_model\n",
    "from src.robustness import (\n",
    "    remove_keywords, synonym_replace,\n",
    "    robustness_test, TRIGGER_KEYWORDS,\n",
    ")\n",
    "from src.trust import compute_trust_score, categorize_trust, generate_trust_report\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# Load model + test data\n",
    "model, vectorizer = load_model(\"../data/processed/model_artifacts.joblib\")\n",
    "split = joblib.load(\"../data/processed/test_split.joblib\")\n",
    "X_test = split[\"X_test\"]\n",
    "y_test = split[\"y_test\"]\n",
    "texts_test = split[\"texts_test\"]\n",
    "\n",
    "# Use 300 samples for robustness testing (or all if fewer)\n",
    "n_samples = min(300, len(texts_test))\n",
    "sample_texts = texts_test[:n_samples]\n",
    "\n",
    "print(f\"Testing robustness on {n_samples} samples ✓\")\n",
    "print(f\"Trigger keywords ({len(TRIGGER_KEYWORDS)}): {sorted(TRIGGER_KEYWORDS)[:10]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13c5dcc",
   "metadata": {},
   "source": [
    "## 1. Perturbation Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e395e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test 1: Keyword Removal\n",
    "print(\"Running keyword removal test...\")\n",
    "kw_results = robustness_test(model, vectorizer, sample_texts, remove_keywords)\n",
    "print(f\"  Flip rate: {kw_results['flip_rate']:.4f} ({kw_results['n_flips']}/{kw_results['n_total']})\")\n",
    "\n",
    "# Test 2: Synonym Replacement\n",
    "print(\"\\nRunning synonym replacement test...\")\n",
    "syn_results = robustness_test(model, vectorizer, sample_texts, synonym_replace, n=3, rng_seed=42)\n",
    "print(f\"  Flip rate: {syn_results['flip_rate']:.4f} ({syn_results['n_flips']}/{syn_results['n_total']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a26800e",
   "metadata": {},
   "source": [
    "## 2. Flip Rate Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7585902c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Bar chart: Flip rates\n",
    "perturbations = [\"Keyword Removal\", \"Synonym Replace\"]\n",
    "flip_rates = [kw_results[\"flip_rate\"], syn_results[\"flip_rate\"]]\n",
    "colors = [\"#F44336\", \"#FF9800\"]\n",
    "\n",
    "bars = axes[0].bar(perturbations, flip_rates, color=colors, edgecolor=\"black\")\n",
    "for bar, val in zip(bars, flip_rates):\n",
    "    axes[0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.005,\n",
    "                 f\"{val:.3f}\", ha=\"center\", fontweight=\"bold\", fontsize=12)\n",
    "axes[0].axhline(0.15, color=\"gray\", linestyle=\"--\", alpha=0.7, label=\"Threshold (15%)\")\n",
    "axes[0].set_ylabel(\"Flip Rate\")\n",
    "axes[0].set_title(\"Prediction Flip Rate by Perturbation\", fontsize=13)\n",
    "axes[0].legend()\n",
    "\n",
    "# Scatter: Original vs Perturbed confidence (keyword removal)\n",
    "axes[1].scatter(kw_results[\"original_conf\"], kw_results[\"perturbed_conf\"],\n",
    "                alpha=0.3, s=10, c=kw_results[\"flip_flags\"].astype(int),\n",
    "                cmap=\"RdYlGn_r\", edgecolors=\"none\")\n",
    "axes[1].plot([0, 1], [0, 1], \"k--\", alpha=0.5)\n",
    "axes[1].set_xlabel(\"Original Confidence\")\n",
    "axes[1].set_ylabel(\"Perturbed Confidence\")\n",
    "axes[1].set_title(\"Confidence Stability (Keyword Removal)\", fontsize=13)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78e645c",
   "metadata": {},
   "source": [
    "## 3. Trust Score Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b1605eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bias FPR gap from notebook 04\n",
    "bias_data = joblib.load(\"../data/processed/bias_results.joblib\")\n",
    "bias_fpr_gap = bias_data[\"bias_fpr_gap\"]\n",
    "\n",
    "# Generate trust reports for 5 sample texts\n",
    "print(\"=== Trust Score Reports ===\\n\")\n",
    "for i in range(min(5, len(sample_texts))):\n",
    "    report = generate_trust_report(\n",
    "        sample_texts[i], model, vectorizer, bias_fpr_gap\n",
    "    )\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"  Prediction:  {report['prediction_label']}\")\n",
    "    print(f\"  Confidence:  {report['confidence']:.3f}\")\n",
    "    print(f\"  Flip Rate:   {report['flip_rate']:.1f}\")\n",
    "    print(f\"  Trust Score: {report['trust_score']:.3f} ({report['trust_label']})\")\n",
    "    print(f\"  Text: {sample_texts[i][:100]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be729c4",
   "metadata": {},
   "source": [
    "## 4. RQ3 Conclusion\n",
    "\n",
    "**H3:** Small perturbations in input text will significantly affect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb013ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_flip = kw_results[\"flip_rate\"]\n",
    "syn_flip = syn_results[\"flip_rate\"]\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"RQ3 CONCLUSION\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  Keyword Removal Flip Rate:  {kw_flip:.4f} ({kw_flip*100:.1f}%)\")\n",
    "print(f\"  Synonym Replace Flip Rate:  {syn_flip:.4f} ({syn_flip*100:.1f}%)\")\n",
    "print(f\"  Threshold:                  15%\")\n",
    "print()\n",
    "\n",
    "if kw_flip > 0.15:\n",
    "    print(\"✓ H3 SUPPORTED: Keyword removal causes >15% prediction flips.\")\n",
    "    print(\"  Model relies significantly on surface-level trigger words.\")\n",
    "else:\n",
    "    print(\"✗ H3 NOT SUPPORTED: Model is relatively robust to keyword removal (<15% flips).\")\n",
    "\n",
    "if syn_flip > 0.15:\n",
    "    print(\"  Synonym replacement also causes significant instability.\")\n",
    "else:\n",
    "    print(\"  Model is robust to synonym replacement.\")\n",
    "\n",
    "# Save robustness results for Streamlit\n",
    "joblib.dump({\n",
    "    \"kw_flip_rate\": kw_flip,\n",
    "    \"syn_flip_rate\": syn_flip,\n",
    "}, \"../data/processed/robustness_results.joblib\")\n",
    "\n",
    "print(\"\\nRobustness testing notebook complete ✓\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
